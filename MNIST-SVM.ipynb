{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Digits - Classification Using SVM\n",
    "\n",
    "In this notebook, we'll explore the popular MNIST dataset and build an SVM model to classify handwritten digits. <a href='http://yann.lecun.com/exdb/mnist/'>Here is a detailed description of the dataset.</a>\n",
    "\n",
    "\n",
    "We will develop a model using Support Vector Machine which should correctly classify the handwritten digits from 0-9 based on the pixel values given as features. Thus, this is a 10-class classification problem. For this problem, we use the MNIST data which is a large database of handwritten digits. The 'pixel values' of each digit (image) comprise the features, and the actual number between 0-9 is the label. \n",
    "Each image is of 28 x 28 pixels, and each pixel forms a feature, there are 784 features. MNIST digit recognition is a well-studied problem in the ML community, and people have trained numerous models (Neural Networks, SVMs, boosted trees etc.) achieving error rates as low as 0.23% (i.e. accuracy = 99.77%, with a convolutional neural network).\n",
    "\n",
    "#### NOTE:\n",
    "Considering the **computational limitations** of the system and the data size at hand, to make our life easier we are going to use 50% of the available data set for model building.<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Understanding and Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "import gc\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 42000 entries, 0 to 41999\n",
      "Columns: 785 entries, label to pixel783\n",
      "dtypes: int64(785)\n",
      "memory usage: 251.5 MB\n"
     ]
    }
   ],
   "source": [
    "# read the dataset\n",
    "digits = pd.read_csv(\"train.csv\")\n",
    "digits.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0         0         0         0   \n",
       "3       0  ...         0         0         0         0         0         0   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# head\n",
    "digits.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "four = digits.iloc[3, 1:]\n",
    "four.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x24ec59bcc10>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "four = four.values.reshape(28, 28)\n",
    "plt.imshow(four, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Side note: Indexing Recall ####\n",
    "`list =    [0, 4, 2, 10, 22, 101, 10]` <br>\n",
    "`indices = [0, 1, 2, 3, ...,        ]` <br>\n",
    "`reverse = [-n           -3  -2   -1]` <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0 220 179   6   0   0   0   0   0   0   0   0   9  77   0   0   0   0]\n",
      " [  0  28 247  17   0   0   0   0   0   0   0   0  27 202   0   0   0   0]\n",
      " [  0   0 242 155   0   0   0   0   0   0   0   0  27 254  63   0   0   0]\n",
      " [  0   0 160 207   6   0   0   0   0   0   0   0  27 254  65   0   0   0]\n",
      " [  0   0 127 254  21   0   0   0   0   0   0   0  20 239  65   0   0   0]\n",
      " [  0   0  77 254  21   0   0   0   0   0   0   0   0 195  65   0   0   0]\n",
      " [  0   0  70 254  21   0   0   0   0   0   0   0   0 195 142   0   0   0]\n",
      " [  0   0  56 251  21   0   0   0   0   0   0   0   0 195 227   0   0   0]\n",
      " [  0   0   0 222 153   5   0   0   0   0   0   0   0 120 240  13   0   0]\n",
      " [  0   0   0  67 251  40   0   0   0   0   0   0   0  94 255  69   0   0]\n",
      " [  0   0   0   0 234 184   0   0   0   0   0   0   0  19 245  69   0   0]\n",
      " [  0   0   0   0 234 169   0   0   0   0   0   0   0   3 199 182  10   0]\n",
      " [  0   0   0   0 154 205   4   0   0  26  72 128 203 208 254 254 131   0]\n",
      " [  0   0   0   0  61 254 129 113 186 245 251 189  75  56 136 254  73   0]\n",
      " [  0   0   0   0  15 216 233 233 159 104  52   0   0   0  38 254  73   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  18 254  73   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  18 254  73   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   5 206 106   0]]\n"
     ]
    }
   ],
   "source": [
    "# visualise the array\n",
    "print(four[5:-5, 5:-5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    4684\n",
       "7    4401\n",
       "3    4351\n",
       "9    4188\n",
       "2    4177\n",
       "6    4137\n",
       "0    4132\n",
       "4    4072\n",
       "8    4063\n",
       "5    3795\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summarise the counts of 'label' to see how many labels of each digit are present\n",
    "digits.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    11.15\n",
       "7    10.48\n",
       "3    10.36\n",
       "9     9.97\n",
       "2     9.95\n",
       "6     9.85\n",
       "0     9.84\n",
       "4     9.70\n",
       "8     9.67\n",
       "5     9.04\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summarise count in terms of percentage \n",
    "100*(round(digits.label.astype('category').value_counts()/len(digits.index), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, each digit/label has an approximately 9%-11% fraction in the dataset and the **dataset is balanced**. This is an important factor in considering the choices of models to be used, especially SVM, since **SVMs rarely perform well on imbalanced data** (think about why that might be the case).\n",
    "\n",
    "Let's quickly look at missing values, if any."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label       0\n",
       "pixel0      0\n",
       "pixel1      0\n",
       "pixel2      0\n",
       "pixel3      0\n",
       "           ..\n",
       "pixel779    0\n",
       "pixel780    0\n",
       "pixel781    0\n",
       "pixel782    0\n",
       "pixel783    0\n",
       "Length: 785, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# missing values - there are none\n",
    "digits.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, let's look at the average values of each column, since we'll need to do some rescaling in case the ranges vary too much."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.00000</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.456643</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.219286</td>\n",
       "      <td>0.117095</td>\n",
       "      <td>0.059024</td>\n",
       "      <td>0.02019</td>\n",
       "      <td>0.017238</td>\n",
       "      <td>0.002857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.887730</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.312890</td>\n",
       "      <td>4.633819</td>\n",
       "      <td>3.274488</td>\n",
       "      <td>1.75987</td>\n",
       "      <td>1.894498</td>\n",
       "      <td>0.414264</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>253.000000</td>\n",
       "      <td>253.00000</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              label   pixel0   pixel1   pixel2   pixel3   pixel4   pixel5  \\\n",
       "count  42000.000000  42000.0  42000.0  42000.0  42000.0  42000.0  42000.0   \n",
       "mean       4.456643      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "std        2.887730      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "min        0.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "25%        2.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "50%        4.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "75%        7.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "max        9.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "\n",
       "        pixel6   pixel7   pixel8  ...      pixel774      pixel775  \\\n",
       "count  42000.0  42000.0  42000.0  ...  42000.000000  42000.000000   \n",
       "mean       0.0      0.0      0.0  ...      0.219286      0.117095   \n",
       "std        0.0      0.0      0.0  ...      6.312890      4.633819   \n",
       "min        0.0      0.0      0.0  ...      0.000000      0.000000   \n",
       "25%        0.0      0.0      0.0  ...      0.000000      0.000000   \n",
       "50%        0.0      0.0      0.0  ...      0.000000      0.000000   \n",
       "75%        0.0      0.0      0.0  ...      0.000000      0.000000   \n",
       "max        0.0      0.0      0.0  ...    254.000000    254.000000   \n",
       "\n",
       "           pixel776     pixel777      pixel778      pixel779  pixel780  \\\n",
       "count  42000.000000  42000.00000  42000.000000  42000.000000   42000.0   \n",
       "mean       0.059024      0.02019      0.017238      0.002857       0.0   \n",
       "std        3.274488      1.75987      1.894498      0.414264       0.0   \n",
       "min        0.000000      0.00000      0.000000      0.000000       0.0   \n",
       "25%        0.000000      0.00000      0.000000      0.000000       0.0   \n",
       "50%        0.000000      0.00000      0.000000      0.000000       0.0   \n",
       "75%        0.000000      0.00000      0.000000      0.000000       0.0   \n",
       "max      253.000000    253.00000    254.000000     62.000000       0.0   \n",
       "\n",
       "       pixel781  pixel782  pixel783  \n",
       "count   42000.0   42000.0   42000.0  \n",
       "mean        0.0       0.0       0.0  \n",
       "std         0.0       0.0       0.0  \n",
       "min         0.0       0.0       0.0  \n",
       "25%         0.0       0.0       0.0  \n",
       "50%         0.0       0.0       0.0  \n",
       "75%         0.0       0.0       0.0  \n",
       "max         0.0       0.0       0.0  \n",
       "\n",
       "[8 rows x 785 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# average values/distributions of features\n",
    "description = digits.describe()\n",
    "description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that the max value of the mean and maximum values of some features (pixels) is 139, 255 etc., whereas most features lie in much lower ranges  (look at description of pixel 0, pixel 1 etc. above).\n",
    "\n",
    "Thus, it seems like a good idea to rescale the features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation for Model Building\n",
    "\n",
    "Let's now prepare the dataset for building the model. We'll only use a fraction of the data else training will take a long time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4200, 784)\n",
      "(37800, 784)\n",
      "(4200,)\n",
      "(37800,)\n"
     ]
    }
   ],
   "source": [
    "# Creating training and test sets\n",
    "# Splitting the data into train and test\n",
    "X = digits.iloc[:, 1:]\n",
    "Y = digits.iloc[:, 0]\n",
    "\n",
    "# Rescaling the features\n",
    "from sklearn.preprocessing import scale\n",
    "X = scale(X)\n",
    "\n",
    "# train test split with train_size=10% and test size=90%\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, train_size=0.10, random_state=101)\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete test set from memory, to avoid a memory error\n",
    "# we'll anyway use CV to evaluate the model, and can use the separate test.csv file as well\n",
    "# to evaluate the model finally\n",
    "\n",
    "# del x_test\n",
    "# del y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building\n",
    "\n",
    "Let's now build the model and tune the hyperparameters. Let's start with a **linear model** first.\n",
    "\n",
    "### Linear SVM\n",
    "\n",
    "Let's first try building a linear SVM model (i.e. a linear kernel). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "\n",
    "# an initial SVM model with linear kernel   \n",
    "svm_linear = svm.SVC(kernel='linear')\n",
    "\n",
    "# fit\n",
    "svm_linear.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 3, 0, 0, 1, 9, 1, 5, 0, 6], dtype=int64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict\n",
    "predictions = svm_linear.predict(x_test)\n",
    "predictions[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3615,    0,   12,    8,    8,   28,   28,    5,    9,    2],\n",
       "       [   0, 4089,   16,   23,    9,    3,    3,   13,   25,    4],\n",
       "       [  54,   48, 3363,   64,   74,   13,   53,   52,   59,   10],\n",
       "       [  20,   28,  121, 3387,    8,  175,    5,   54,   58,   44],\n",
       "       [  12,   12,   26,    2, 3399,    7,   41,   41,    4,  158],\n",
       "       [  49,   42,   32,  177,   41, 2899,   54,   14,   82,   28],\n",
       "       [  36,   16,   55,    5,   34,   37, 3486,    3,   21,    0],\n",
       "       [   9,   27,   37,   22,   70,   10,    4, 3619,   14,  142],\n",
       "       [  26,   86,   71,  137,   24,  137,   29,   26, 3096,   33],\n",
       "       [  38,   11,   39,   26,  182,   19,    1,  207,   27, 3228]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluation: accuracy\n",
    "# C(i, j) represents the number of points known to be in class i \n",
    "# but predicted to be in class j\n",
    "confusion = metrics.confusion_matrix(y_true = y_test, y_pred = predictions)\n",
    "confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9042592592592592"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# measure accuracy\n",
    "metrics.accuracy_score(y_true=y_test, y_pred=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.95      3715\n",
      "           1       0.94      0.98      0.96      4185\n",
      "           2       0.89      0.89      0.89      3790\n",
      "           3       0.88      0.87      0.87      3900\n",
      "           4       0.88      0.92      0.90      3702\n",
      "           5       0.87      0.85      0.86      3418\n",
      "           6       0.94      0.94      0.94      3693\n",
      "           7       0.90      0.92      0.91      3954\n",
      "           8       0.91      0.84      0.88      3665\n",
      "           9       0.88      0.85      0.87      3778\n",
      "\n",
      "    accuracy                           0.90     37800\n",
      "   macro avg       0.90      0.90      0.90     37800\n",
      "weighted avg       0.90      0.90      0.90     37800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# class-wise accuracy\n",
    "class_wise = metrics.classification_report(y_true=y_test, y_pred=predictions)\n",
    "print(class_wise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "198"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run gc.collect() (garbage collect) to free up memory\n",
    "# else, since the dataset is large and SVM is computationally heavy,\n",
    "# it'll throw a memory error while training\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-Linear SVM\n",
    "\n",
    "Let's now try a non-linear model with the RBF kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rbf kernel with other hyperparameters kept to default \n",
    "svm_rbf = svm.SVC(kernel='rbf')\n",
    "svm_rbf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9250793650793651\n"
     ]
    }
   ],
   "source": [
    "# predict\n",
    "predictions = svm_rbf.predict(x_test)\n",
    "\n",
    "# accuracy \n",
    "print(metrics.accuracy_score(y_true=y_test, y_pred=predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy achieved with a non-linear kernel is slightly higher than a linear one. Let's now do a grid search CV to tune the hyperparameters C and gamma.\n",
    "\n",
    "### Grid Search Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=SVC(),\n",
       "             param_grid={'C': [1, 10, 100], 'gamma': [0.01, 0.001, 0.0001]},\n",
       "             return_train_score=True, scoring='accuracy')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# conduct (grid search) cross-validation to find the optimal values \n",
    "# of cost C and the choice of kernel\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = {'C':[1, 10, 100], \n",
    "             'gamma': [1e-2, 1e-3, 1e-4]}\n",
    "\n",
    "# instantiate a model \n",
    "svc_grid_search = svm.SVC(kernel=\"rbf\")\n",
    "\n",
    "# create a classifier to perform grid search\n",
    "clf = GridSearchCV(svc_grid_search, param_grid=parameters, scoring='accuracy',return_train_score=True)\n",
    "\n",
    "# fit\n",
    "clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28.450418</td>\n",
       "      <td>0.341113</td>\n",
       "      <td>3.898005</td>\n",
       "      <td>0.009845</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'C': 1, 'gamma': 0.01}</td>\n",
       "      <td>0.719048</td>\n",
       "      <td>0.759524</td>\n",
       "      <td>0.686905</td>\n",
       "      <td>...</td>\n",
       "      <td>0.725000</td>\n",
       "      <td>0.023450</td>\n",
       "      <td>9</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.899185</td>\n",
       "      <td>0.106437</td>\n",
       "      <td>2.560033</td>\n",
       "      <td>0.020262</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'C': 1, 'gamma': 0.001}</td>\n",
       "      <td>0.925000</td>\n",
       "      <td>0.921429</td>\n",
       "      <td>0.908333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.918095</td>\n",
       "      <td>0.006709</td>\n",
       "      <td>3</td>\n",
       "      <td>0.966369</td>\n",
       "      <td>0.969643</td>\n",
       "      <td>0.969345</td>\n",
       "      <td>0.969643</td>\n",
       "      <td>0.967560</td>\n",
       "      <td>0.968512</td>\n",
       "      <td>0.001323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.987808</td>\n",
       "      <td>0.235789</td>\n",
       "      <td>3.333790</td>\n",
       "      <td>0.022010</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>{'C': 1, 'gamma': 0.0001}</td>\n",
       "      <td>0.876190</td>\n",
       "      <td>0.884524</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.876905</td>\n",
       "      <td>0.006547</td>\n",
       "      <td>6</td>\n",
       "      <td>0.900595</td>\n",
       "      <td>0.898512</td>\n",
       "      <td>0.897917</td>\n",
       "      <td>0.900298</td>\n",
       "      <td>0.898214</td>\n",
       "      <td>0.899107</td>\n",
       "      <td>0.001114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28.023024</td>\n",
       "      <td>0.288314</td>\n",
       "      <td>3.871043</td>\n",
       "      <td>0.006473</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'C': 10, 'gamma': 0.01}</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.775000</td>\n",
       "      <td>0.709524</td>\n",
       "      <td>...</td>\n",
       "      <td>0.741667</td>\n",
       "      <td>0.021176</td>\n",
       "      <td>7</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.901721</td>\n",
       "      <td>0.421665</td>\n",
       "      <td>2.401065</td>\n",
       "      <td>0.071170</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'C': 10, 'gamma': 0.001}</td>\n",
       "      <td>0.941667</td>\n",
       "      <td>0.927381</td>\n",
       "      <td>0.915476</td>\n",
       "      <td>...</td>\n",
       "      <td>0.925238</td>\n",
       "      <td>0.011076</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999107</td>\n",
       "      <td>0.999405</td>\n",
       "      <td>0.999405</td>\n",
       "      <td>0.999702</td>\n",
       "      <td>0.999405</td>\n",
       "      <td>0.999405</td>\n",
       "      <td>0.000188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.022337</td>\n",
       "      <td>0.081874</td>\n",
       "      <td>2.159822</td>\n",
       "      <td>0.014124</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>{'C': 10, 'gamma': 0.0001}</td>\n",
       "      <td>0.921429</td>\n",
       "      <td>0.925000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.915476</td>\n",
       "      <td>0.009066</td>\n",
       "      <td>4</td>\n",
       "      <td>0.955655</td>\n",
       "      <td>0.960714</td>\n",
       "      <td>0.961310</td>\n",
       "      <td>0.959226</td>\n",
       "      <td>0.958631</td>\n",
       "      <td>0.959107</td>\n",
       "      <td>0.001980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>28.015293</td>\n",
       "      <td>0.325704</td>\n",
       "      <td>3.870495</td>\n",
       "      <td>0.005818</td>\n",
       "      <td>100</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'C': 100, 'gamma': 0.01}</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.775000</td>\n",
       "      <td>0.709524</td>\n",
       "      <td>...</td>\n",
       "      <td>0.741667</td>\n",
       "      <td>0.021176</td>\n",
       "      <td>7</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.537400</td>\n",
       "      <td>0.092255</td>\n",
       "      <td>2.339604</td>\n",
       "      <td>0.034676</td>\n",
       "      <td>100</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'C': 100, 'gamma': 0.001}</td>\n",
       "      <td>0.938095</td>\n",
       "      <td>0.929762</td>\n",
       "      <td>0.914286</td>\n",
       "      <td>...</td>\n",
       "      <td>0.924048</td>\n",
       "      <td>0.010999</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.586721</td>\n",
       "      <td>0.069678</td>\n",
       "      <td>1.842975</td>\n",
       "      <td>0.028390</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>{'C': 100, 'gamma': 0.0001}</td>\n",
       "      <td>0.908333</td>\n",
       "      <td>0.920238</td>\n",
       "      <td>0.886905</td>\n",
       "      <td>...</td>\n",
       "      <td>0.905952</td>\n",
       "      <td>0.015040</td>\n",
       "      <td>5</td>\n",
       "      <td>0.997917</td>\n",
       "      <td>0.997321</td>\n",
       "      <td>0.997024</td>\n",
       "      <td>0.998512</td>\n",
       "      <td>0.997917</td>\n",
       "      <td>0.997738</td>\n",
       "      <td>0.000519</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "0      28.450418      0.341113         3.898005        0.009845       1   \n",
       "1       8.899185      0.106437         2.560033        0.020262       1   \n",
       "2      12.987808      0.235789         3.333790        0.022010       1   \n",
       "3      28.023024      0.288314         3.871043        0.006473      10   \n",
       "4       7.901721      0.421665         2.401065        0.071170      10   \n",
       "5       6.022337      0.081874         2.159822        0.014124      10   \n",
       "6      28.015293      0.325704         3.870495        0.005818     100   \n",
       "7       7.537400      0.092255         2.339604        0.034676     100   \n",
       "8       4.586721      0.069678         1.842975        0.028390     100   \n",
       "\n",
       "  param_gamma                       params  split0_test_score  \\\n",
       "0        0.01      {'C': 1, 'gamma': 0.01}           0.719048   \n",
       "1       0.001     {'C': 1, 'gamma': 0.001}           0.925000   \n",
       "2      0.0001    {'C': 1, 'gamma': 0.0001}           0.876190   \n",
       "3        0.01     {'C': 10, 'gamma': 0.01}           0.733333   \n",
       "4       0.001    {'C': 10, 'gamma': 0.001}           0.941667   \n",
       "5      0.0001   {'C': 10, 'gamma': 0.0001}           0.921429   \n",
       "6        0.01    {'C': 100, 'gamma': 0.01}           0.733333   \n",
       "7       0.001   {'C': 100, 'gamma': 0.001}           0.938095   \n",
       "8      0.0001  {'C': 100, 'gamma': 0.0001}           0.908333   \n",
       "\n",
       "   split1_test_score  split2_test_score  ...  mean_test_score  std_test_score  \\\n",
       "0           0.759524           0.686905  ...         0.725000        0.023450   \n",
       "1           0.921429           0.908333  ...         0.918095        0.006709   \n",
       "2           0.884524           0.866667  ...         0.876905        0.006547   \n",
       "3           0.775000           0.709524  ...         0.741667        0.021176   \n",
       "4           0.927381           0.915476  ...         0.925238        0.011076   \n",
       "5           0.925000           0.900000  ...         0.915476        0.009066   \n",
       "6           0.775000           0.709524  ...         0.741667        0.021176   \n",
       "7           0.929762           0.914286  ...         0.924048        0.010999   \n",
       "8           0.920238           0.886905  ...         0.905952        0.015040   \n",
       "\n",
       "   rank_test_score  split0_train_score  split1_train_score  \\\n",
       "0                9            1.000000            1.000000   \n",
       "1                3            0.966369            0.969643   \n",
       "2                6            0.900595            0.898512   \n",
       "3                7            1.000000            1.000000   \n",
       "4                1            0.999107            0.999405   \n",
       "5                4            0.955655            0.960714   \n",
       "6                7            1.000000            1.000000   \n",
       "7                2            1.000000            1.000000   \n",
       "8                5            0.997917            0.997321   \n",
       "\n",
       "   split2_train_score  split3_train_score  split4_train_score  \\\n",
       "0            1.000000            1.000000            1.000000   \n",
       "1            0.969345            0.969643            0.967560   \n",
       "2            0.897917            0.900298            0.898214   \n",
       "3            1.000000            1.000000            1.000000   \n",
       "4            0.999405            0.999702            0.999405   \n",
       "5            0.961310            0.959226            0.958631   \n",
       "6            1.000000            1.000000            1.000000   \n",
       "7            1.000000            1.000000            1.000000   \n",
       "8            0.997024            0.998512            0.997917   \n",
       "\n",
       "   mean_train_score  std_train_score  \n",
       "0          1.000000         0.000000  \n",
       "1          0.968512         0.001323  \n",
       "2          0.899107         0.001114  \n",
       "3          1.000000         0.000000  \n",
       "4          0.999405         0.000188  \n",
       "5          0.959107         0.001980  \n",
       "6          1.000000         0.000000  \n",
       "7          1.000000         0.000000  \n",
       "8          0.997738         0.000519  \n",
       "\n",
       "[9 rows x 22 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# results\n",
    "cv_results = pd.DataFrame(clf.cv_results_)\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA7YAAAGHCAYAAACEQ865AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzde5xddX3v/9dnrpncJpchIRdCEgJyD4QhCEEBUYQqBVo9glorokgVe44ereivXmr7O/XA6a+Xn7aU9iDHasWWlkrPsYJtEQTUZoLcLzoJAXIhZHKZXCeZy/f8sfbM7Ewmk0kyO/v2ej4e+7H3Xuu71v5MLp/kvdda3xUpJSRJkiRJKlc1xS5AkiRJkqQjYbCVJEmSJJU1g60kSZIkqawZbCVJkiRJZc1gK0mSJEkqawZbSZIkSVJZM9hKkiRJksqawVaHJSKujYifRcTOiHg99/pjERHFrm0sRMRZEbEiInblns8aYWxjRNwZEdsi4rWI+NSQ9XdExIsR0RcRHyx48ZKOiP1tn7EH628H3FdEnB4R90dER0SkQv5Mkg7O3rbP2MPubbn1n8xt15nbT2Peupsjoi0i9kTEXWP+g+qADLY6ZBHxX4E/BW4DjgVmAjcBy4CGIpY2JiKiAfge8C1gKvC/gO/llg/ny8CJwPHAJcDvRMTleeufBD4GPF6omiWNDfvbfr7MAfrbKPbVDfwdcENBfhhJo2Zv28+XOczeFhFvB24BLgXmAwuB38vb9zrgD4A7x+wH1OiklHz4GPUDaAZ2Ar8+wph3AD8HtgGvAl/OWzcfSMD1uXVbyBrrucBTwFbga3njPwg8Cvxxbt0q4ILc8leB14HfHM1nH8LPeBmwFoi8Za8Alx9g/Frgsrz3vw/cPcy4R4APFvv30IcPH8M/7G/Djj9gfxvtvoBF2X83iv977MNHNT7sbcOOP+zeBvwt8N/y1l0KvDbMZ/wBcFexf/+r6eERWx2q84FGsm+yDmQn8AFgClmz+q2IuHrImPPIvil7D/AnwP8DvBU4DfhPEXHRkLFPAdPJmsndZM10EfB+4GsRMXE0nx0RW0d43JIbdhrwVMp1pZyncsv3ERFTgdlkR2X7PTncWEklz/6WZxT9bdT7klRU9rY8Y9DbThtm25kRMX3oZ+noMtjqULUAHSmlnv4FEfFYrrnsjog3p5R+lFJ6OqXUl1J6CvgOcNGQ/fx+SqkrpfQAWUP7Tkrp9ZTSWuDHwNl5Y19KKX0jpdQLfBc4DvhKSmlPbvu9ZI2Sg312SmnKCI+v5oZNBDqH1NsJTBrm12Ni3vqDjZVU2uxv+zpYfzuUfUkqHnvbvo60tw1d3//a3ldkBlsdqk1AS0TU9S9IKV2QUpqSW1cTEedFxIMRsTEiOslOV2kZsp8Nea93D/N+4ghjSSkNO36Un30wO4DJQ5ZNBrYfYGz/+oONlVTa7G/7j+1fP9zYQ9mXpOKxt+0/tn/9cGMPtq+h6/tf2/uKzGCrQ/UTYA9w1Qhj/ha4DzgupdQM3A4crRn3RvzsiNgxwuPzuWHPAmdG7DNL4Jm55ftIKW0B1gOL8xYvHm6spJJnf8sziv426n1JKip7W54x6G3PDrPthpTSpkP7sTXWDLY6JCmlrWQzv/15RLwrIiZGRE1k06BPyA2bBGxOKXVFxFLgvUexxBE/O6U0cYTHf8sN+xHQC/x2ZNPB35xb/u8H+MxvAr8bEVMj4mTgI8Bd/SsjoiEixpE16fqIGBcR/t2TSoz9bVgj9bcR9xWZceRmXM31vkYkHVX2tmEddm/LbXtDRJyau173d9n3/311ud5XC9Tmet/A0XIVjv+51iFLKd0KfAr4HbKZ7TYAfwl8FniM7NY2X4mI7cAXyW73cLQc8WenlPYCV5NNZLAV+BBwdW45EfG+iMj/BvBLwErgZeAh4LaU0g/y1j9AdsrNBcAduddvPtS6JBWe/W30/e1g+yK7jcZuBo9y7AZePNSaJR05e9vY9bbcuFuBB3Pbv5zbX7/fJet3t5BNlLU7t0wFFmmfCb8kSZIkSSovHrGVJEmSJJW1ggXbiLgzIl6PiGcOsD4i4s8ioj0inoqIJXnrLo+IF3Prbhlue0kqBfY6SdXCfieplBXyiO1dwOUjrL+C7CbPJwI3An8BEBG1wNdz608FrouIUwtYpyQdibuw10mqDndhv5NUogoWbFNKDwObRxhyFfDNlPkpMCUiZgFLgfaU0qrcRdp3M/L05JJUNPY6SdXCfieplBXzGts5wKt579fklh1ouSSVI3udpGphv5NUNMW8p9JwN31OIywfficRN5Kd7sKECRPOOfnkk0f36Z1roXvX6MZKKh3146F59P8fWrFiRUdK6ZgCVnQwxe11Kn99PbB3V/ZvVvfO7HVfT4E+LIZ5OfSP6nBjhhuXt2w04/ZbPNpxBxgbI9R9wDFDxh7w12C4MUc6Lrc8f9XkOTDK256XQK+DMeh39jqpyvR2Q239qIeP1OuKGWzXAMflvZ8LrCO7kftwy4eVUrqD7N6gtLa2pra2trGvVFLZioiXi1yCvU6jt3cXrH8S1q4YfGzN/RGOGjjmFJizBOackz2a5+bCWRzZ8wEDnspFCfQ6GIN+Z6+TKtzuLbD6EVj1I1j1EGxaDR/7GcwY3ZdYI/W6Ygbb+4CbI+Ju4DygM6W0PiI2AidGxAJgLXAt8N4i1ilJR8Jep+H19cLGF7LwuqYN1j4Orz8HqTdb3zwvC7HnfjgLsbMWQ+PE4tYsjcx+J2lf3V3w6k8Hg+z6JyD1Qf0EmL8MzvkgjJ82Jh9VsGAbEd8BLgZaImIN8CWgHiCldDvwfeBXgHZgF3B9bl1PRNwM3A/UAnemlJ4tVJ2SdCTsdRqVlKDz1bwjsY/DuieyU4sBxjVn4fUNn8qeZy+BSTOLW7M0hP1O0kH19WbhddVDWZh99WfQ0wU1dTD3XHjz78DCi7N/6+oaxvSjCxZsU0rXHWR9Aj5+gHXfJ2uOklTS7HUa1q7NsO7xLMD2h9mdG7N1tY0w60xY8huDpxRPW+jpwCp59jtJ+0kJNrXnjsj+CFb/GLo6s3UzToPWG7Ige/z50DipoKUU81RkSZLKX/dueO3pfa+L3bwqtzLgmDfAiZcNXhs747Qx/5ZakqSjZvtrg0dkX3oItq3NljfPg1N+NQuyC94ME2cc1bIMtpIkjVZfL3T8Yt8Qu+HZwVmKJ8/JAuySD+Suiz0Lxk0ubs2SJB2Jrk5Y/WgWYlf9KJsfAqBpKiy4CBZ+OguzUxcU9ewjg60kScNJKfsWep/rYn8Oe3dk6xubYc7ZsOw/D14XO3lWcWuWJOlI9eyBV/9jMMiufTyb2LCuKTul+Kz3ZoH22DOhZnS3JDsaDLaSJAHs3pq7LnbF4LWxOzZk62ob4Ngzsn/MB66LPaGk/kGXJOmw9PXBhqcHZy5++THo2Z3dZm7OOfCmT2VB9rilUNdY7GoPyGArSao+PXv2vy52U/vg+paT4IS35ELsEph5ekn/Yy5J0qilBFteGgyyLz0Muzdn6445ObucZuHF2e14xjUXsdBDY7CVJFW2vr4stOaH2Neehr7ubP3EmTCndfBo7KyzoGlKcWuWJGks7dg4eGrxSw/B1ley5ZNmw0mXD074VMaX1BhsJUmVZdv6fUPsup/Dnm3ZuoZJMPssOP/jg6cUT57trXYkSZVlz47slOL+ILvhmWx5YzMseBNc8NtZmJ2+qGL+DTTYSpLKV9e2LLjmT/C0fV22rqYuO4X4jHcPhtiWE6Gmtrg1S5I01nq7YU3bYJBdszybsb+2Eea9ES79YhZkZ51Vsf8OGmwlSeWhZ2/2jXP+5E4dvwBStn7aCTD/wsEQe+wZUD+uqCVLklQQfX3w+nODpxevfhS6dwKRnZl0wSeyCZ/mvRHqm4pd7VFhsJUklZ6+Pti8ash1sU9B795s/YRjsutiz3h3NrnT7LNh/LTi1ixJUiFteTnvOtmHYefGbPn0RXDWdVmQnX9h1f57aLCVJBXf9g1Drot9PLshPED9hCy4nnfT4NHY5rkVc02QJEnD2rkJVj+czVy86kfZTMaQTXq48JLs1OKFF2X/JspgK0k6yvZsh3VP7Htd7LY12bqohZmnwWm/Nhhij3lDxV4PJEnSgL274JXHBoPsa08DKZv4cP6F2Re8Cy/Kbsnjl7v7MdhKkgqntzu7BmhN2+B1sRtfYOC62KkLsut/8q+LbRhf1JIlSToqenuyCRBX/Sh7rPmP7JKbmno47jy45PPZUdnZS6DW2HYw/gpJksZG/w3f+wPs2hWw/kno6crWj5+ehdfTrs6eZy+BCdOLW7MkSUdLSrDxxcGZi1c/Mng7umPPhPM+mgXZeedDw4QiFlqeDLaSpMOzY2N2LWz+tbG7t2Tr6pqyWRnP/XA2udOcc2DK8Z46JUmqLp1rslOLX3ooe97xWrZ86nw4/deyIDv/zX7ROwYMtpKkg9u7Mzv6mh9it76SrYsamHEqnHJl3nWxp3jalCSp+uzekh2J7T+9eFN7tnx8S3Z97IKLsuep84tYZGXyfx2SpH319sDG5/ed3On15yD1ZeunzMvC69Ibs+dZiz1lSpJUnbq74NWf5oLsQ7D+iezfy/oJcPwFcM712VHZGadCTU2Ri61sBltJqmYpwdaXBwPs2hXZjMU9u7P1TVOz8HryOwavi514THFrliSpWPp6s/DaH2Rf+Sn07oGauuz+6m/+neyI7JxWqGsodrVVxWArSdVk1+ZcgG0bPCK7a1O2rm5cdvS19frcKcVLslmLvS5WklStUspOJ+4/tXj1jwfvsz7jtGwuiYUXZUdnGycVs9KqZ7CVpErVs2fI/WJXDN7cnYAZp8Abrhi8LnbGqVBbX9SSJUkquu2vDd5L9qWHYNvabHnzcdl8EgsvgQVvhokzilqm9mWwlaRKteVluPOy7PXkudkR2P6jsbMW+82yJEmQHYFd/Whu5uIf5e63TnY5zoI3w8JPZ5M+TVvoWUwlzGArSZVq+iK49jtZoJ10bLGrkSSpNPTsgVf/YzDIrn0cUm92q7rjz4fF12UTPh17phM+lRGDrSRVqpoaOPlXil2FJEnF1dcHrz01GGRf/kk2SWLUZJMiXvjJLMgetxTqGotcrA6XwVaSJElS5Ugpm1Oif+bilx6G3ZuzdS1vgCUfyE34tAyaphS1VI0dg60kSZKk8rbj9SzA9ofZzley5ZNmw0mXZ0F2wUUweVZRy1ThGGwlSZIklZc9O+DlxwZnLt7wTLa8sRkWvAmW/XYWZFtOdMKnKmGwlSRJklTaerthTdtgkF2zHPp6oLYR5p0Hl34RFlyczfpfa8SpRv6uS5IkSSo9e3fC0/fAC/87ux1P904gYPZZcP7N2YRP894I9U1FLlSlwGArSZIkqXS8/jy03QlP3g17tsHUBbD42izIzr8Qxk8rdoUqQQZbSZIkScXVsxeevy8LtC8/CrUNcOpV0HpDdlTW62R1EAZbSZIkScWx5WVYcRf8/G9g50aYcjy89ctw9m/AhJYiF6dyYrCVJEmSdPT09cIvfwht/zN7jshuydN6A5zwFqipKXaFKkMFDbYRcTnwp0At8Ncppa8OWT8VuBM4AegCPpRSeia3bjWwHegFelJKrYWsVZIOl71OUjWw1+mI7XgdHv8mrPhf2X1mJ86EN38alvwmTDmu2NWpzBUs2EZELfB14G3AGmB5RNyXUnoub9jngSdSStdExMm58Zfmrb8kpdRRqBol6UjZ6yRVA3udDltK2TWzy/8nPP/P0NcN898El30FTn4n1NYXu0JViEIesV0KtKeUVgFExN3AVUB+AzwV+EOAlNILETE/ImamlDYUsC5JGkv2OknVwF6nQ9PVmc1q3HYnbHwBGpvh3A9D64fgmJOKXZ0qUCFPYJ8DvJr3fk1uWb4ngV8DiIilwPHA3Ny6BDwQESsi4sYC1ilJR8JeJ6ka2Os0OuuegPs+AX90MvzL72T3mP3Vr8F/fQGu+KqhVgVTyCO2w83JnYa8/yrwpxHxBPA08HOgJ7duWUppXUTMAH4YES+klB7e70Oy5ngjwLx588aseEkaJXudpGpgr9OB7d0Fz96bTQa1dgXUNcEZ78qOzs5ZUuzqVCUKGWzXAPlXgc8F1uUPSCltA64HiIgAXso9SCmtyz2/HhH3kp0Cs18DTCndAdwB0NraOrTBSlKh2eskVQN7nfbX8cvsVOMnvp2detxyElz+32HxtdA0pdjVqcoUMtguB06MiAXAWuBa4L35AyJiCrArpbQX+DDwcEppW0RMAGpSSttzry8DvlLAWiXpcNnrJFUDe50yvd3wwv/Jjs6+9DDU1MEpV2a36pl/YXbrHqkIChZsU0o9EXEzcD/ZtPB3ppSejYibcutvB04BvhkRvWSTD9yQ23wmcG/2ZR91wN+mlH5QqFol6XDZ6yRVA3ud6FwLK+7Kbtez4zVoPg7e8rtw9gdg0sxiVycRKVXOWR6tra2pra2t2GVIKiERsaLS7pdor5M0lL1OBdHXB6v+HZbfCb/4l+zWPYveCufeACdeBjW1xa5QVWakXlfIU5ElSZIklZudm+CJb0HbN2DLSzC+BS74bWi9HqbOL3Z10rAMtpIkSVK1Swle/Y/s2tln/wl698C8C7LTjU+5Euoai12hNCKDrSRJklSt9myHp/4um914wzPQMAmWfCC7Vc/MU4tdnTRqBltJkiSp2rz2TBZmn/ou7N0Bx54B7/wTOOPd0Dix2NVJh8xgK0mSJFWD7i547nvZ6cav/gxqG+H0X8tu1TO31Vv1qKwZbCVJkqRKtnlVNhHUE9+GXZtg2kK47A/grPfB+GnFrk4aEwZbSZIkqdL09sAv74fl/xNW/htELbzhiuxWPQsuhpqaYlcojSmDrSRJklQptr8Gj38TVtwF29bCpFlw8eeyCaEmzy52dVLBGGwlSZKkcpYSvPRwdu3sC/8H+npg4SVwxX+Hk66AWv/Lr8rnn3JJkiSpHO3eAk98J5vdeNMvoWkqnHdTdque6ScUuzrpqDLYSpIkSeVk7Yrs2tln/gF6umDuuXD17XDa1VDfVOzqpKIw2EqSJEmlbu9OePqe7Ojs+iegfgIsvja7Vc+sM4tdnVR0BltJkiSpVG18MTs6++TdsKcTZpwKv/I/4Mz3wLjJxa5OKhkGW0mSJKmU9OyFF/4Zlt8JLz8CtQ1w6lXZ0dl5b4SIYlcolRyDrSRJR0lfX2JXdy879/TkHr3s3Jt7vXff5bv29rBjTw+79vbmnnvYsaeXXXnLevsSEVATQU3uOfJe1wTZ+5rsfW1E3vi81zXDb9s/7kDrY79x+XWMoq4Iakfcd25ZzeD+aofuu2bkbWsPsn7fWgf3eaCfceiv2T4/f//6YX8dBvdXe5D1qmJbX8lu0/P438DO12HK8fDWL8NZ74eJxxS5OKm0GWwlSTqAPT297NrTu1/A3DeU5gLpkIA6uF0ukO7N9jFajXU1TGysY3xjLRMa6pjQWEdzUz2zm8cxobGOCQ211NXW0JcSKUFfSrkHpJTo62Pf9ynRmxt3oPV9A+uz596+7NHdO2Tf6QDb9g2/n2G37cvfz/7rUyrgb2yJ6w+9P/38pbRMbCx2OSq0vl5o/7fsVj2/uD87Gnvi2+HcG+CES6GmptgVSmXBYCtJqgj9R0N37Tnwkc7+5YNBdP/X+dt1944uXdUEA+FzfGNtFkgbapk9ZRzjc8snNNRmz4255wMsH98wGFqrWdonGO8bgPtSIvWNEJqHhPOR1vflh/1EbvwB1u/3ZQD0Dmw7uP5A++6vZ6T1+V8WjG+oLfZvgwppx0b4+TezI7RbX4EJM+BN/xXO+SBMOa7Y1Ullx2ArSSqKvT19+4bK/COhQ4507ug/Arq3h10HOIX3SI+GTm6qZ1be0dDxjXUDAXUwiA7/elx9jaeQjrHoP00Xf11VQVKClx/Ljs4+dx/0dcP8N8Fbfw9OfifUNRS7QqlsGWwlSQc13NHQ/Y967ntK7vCn8A4G0iM9Gjqr2aOhkspEVyc8+d3sVj0bn4fGZjj3w9D6ITjmpGJXJ1UEg60kVaie3j5e29ZVlKOhA2EyFzAnjasbCKITGz0aKqlKrH8yu1XP0/dA906YfTb86tfg9F+HhvHFrk6qKAZbSapQa7bs5uL/8aMRx4z10dDxDbXUezRUUjXr3g3P3psF2rVtUNcEZ/x6dqueOUuKXZ1UsQy2klShjpnUyK3vOtOjoZJ0NGxamZ1q/PNvQddWaDkJLv8qLL4WmqYWuzqp4hlsJalCTWis4z+1OrOmJBVMbze8+C/ZZFCrfgQ1ddkkUOfekE0K5ReHh2XTjj08tnITj63s4NH2TWzY1sXkpnqam+qZPC679VlzU/3Asmz54PvJTYNjJjbW+QVulTDYSpIkSYeicy08/r/g8W/C9vUweS685Xfh7A/ApJnFrq7s7NzTw3+s3sxj7R080r6J59dvA2DSuDreuHA6l59+LNu7uuncnT06duxl5caddO7uZltX94j3va4J8kJxXhBuqjvA8sHXk8bVeXlNGTHYSpIkSQfT1werHsxON37xXyD1waK3wjv/GE68DGq87/Bodff28eSrW3mkvYPH2jfx81e30N2baKitoXX+VD7z9jdwwQnTOWNO80Fnse/rS+zY20Pnrizkdu7uZtvubrbt7hkIwtvyQvG23d2s79zNtq5s/d6evhH3P6GhdiDwTh4mHOcfMW4ev29Q9nKfo8tgK0mSJB3Irs3ZdbMrvgGbV8H46XDBJ+CcD8K0BcWuriyklHhxw3Ye+WUHj63cxM9WbWLn3l4i4Iw5zdxw4UIuXNRC6/ypjKs/tC8IamoiOw15XP1h1dbV3cu23d37h+Bd3QPhtz8Qd+7uZs2WXTy/Plu+Y0/PiPtuqK0Z4cjwkFDclH8qdT2TGuuoqTEUHwqDrSRJkpQvJVizPJvZ+Nl7oXcPzDsfLv48nPqrUNdY7ApL3potu3i0PbtG9rGVHXTs2AvAwpYJXLNkDhcuauGNC6czZXxDUescV1/LuPpaZkwed8jb9vT2sb3rQEeG912+bXc3W3bt5eVN/adQ99Dbd+BzqCNgUmPdfkeBhwbg4a45njyunoa66juF2mArSZIkAezZAU//HSy/EzY8DQ2TYMlvQOuHYOZpxa6upG3euZefrNzEoys7eLS9g5c37QKyGfovXNTCstxj9pSmIlc6dupqa5g6oYGpEw49nKeU2Lm3N+/o8L6nS28bCMWDAbn99R0Dr/cc5BTqpvra/Y4O738q9f5HkCePq2d8Q21ZnkJtsJUkSVJ12/BcNrPxk9+Fvdth5hnZtbNn/CdonFjs6krSrr09LF+9JXdUtoPn1m8jJZjYmE349MEL5nPhohYWzZhYliGp0CKCiY11TGysY85hhP2u7t6BI8Gdu3uyMLzPadT7Hj1et7WL59dvZ1tXN9u7Rj6Fur42BmaZHs1s1PnheNK4emqLdAq1wVaSJEnVp2cPPHdfFmhf+QnUNsLpvwatN8DcVm/VM0RPbx9PrukcCLKPvzI44dOS46fwqbeexLITWzhzFBM+6cgNnEI96dBPoe7tS2zvGnmCrc4hR4xf3bxrYHnPCKdQQzab9Wgn2ZrcVM8psyYxvuHIY6nBVpIkSdVj80vZRFA//xbs2gTTFsJlfwBnvQ/GTyt2dSUjpcQvNuwYCLI/e2kzO/b0EAGnzZ7Mh5YtYNmiFs6dP42mBmeELie1NcGU8Q2HdX1zSolde3sPOslW/hHklzp2DoTo3d29++3zf3/iQk6f03zEP5fBVpIkSZWtrxd+cX92dLb93yBq4A1XwLk3wIKLocYjjABrt+4eCLKPrdzExu17AJg/fTxXnTWbZYtaOH/h9MO6plSVISKY0FjHhMY6ZjUf+inUe3v69js6PL9lwpjUVtBgGxGXA38K1AJ/nVL66pD1U4E7gROALuBDKaVnRrOtJJUKe52kalCWvW77Bnj8m7DiLti2BibNgos+C+f8JkyefVRKKGVbd2UTPj2SC7IvdewEoGViQzbZ0wktXLBoOnOnji9ypaoUDXU1tExspGXi2M8sXrBgGxG1wNeBtwFrgOURcV9K6bm8YZ8HnkgpXRMRJ+fGXzrKbSWp6Ox1kqpBWfW6lGD1j7Nb9bzwv6GvBxZeDJf/YXaUtvbw7ndaCXbv7WX56s0DMxc/uy6b8GlCQy1vXDid97/xeC5c1MJJM53wSeWnkEdslwLtKaVVABFxN3AVkN/ETgX+ECCl9EJEzI+ImcDCUWwrSaXAXiepGpR+r9u9FZ78DrTdCR2/gKapcN5N2a16pp8wph9VLnp6+3hqbSePtXfwSHsHj7+8lb29fdTXBmfPm8p/ufQkLjxxOmfOnUK9Ez6pzBUy2M4BXs17vwY4b8iYJ4FfAx6JiKXA8cDcUW4LQETcCNwIMG/evDEpXJIOgb1OUjUo3V63azP88Avw9D9Az26Yey5cfTucdjXUV849U0cjpUT76zt4pL2DR9s38bNVm9i+J7u1y6mzJvPBZfO54ITpLF0wbUxmoZVKSSH/RA93/sLQuaG/CvxpRDwBPA38HOgZ5bbZwpTuAO4AaG1tHXnuaUkae/Y6SdWgdHtdw0RY/Sgsfk92dHbW4lFtVinW5SZ8emzlJh5t7+D13IRP86aN552LZ7Ns0XTOXzid6QW4plEqJYUMtmuA4/LezwXW5Q9IKW0DrgeI7ET+l3KP8QfbVpJKhL1OUjUo3V5X1wCfWAE11XHLmc5d3fxkVXZE9tH2DlblJnyaPqGBCxa1sOyE6Sxb1MJx05zwSdWlkMF2OXBiRCwA1gLXAu/NHxARU4BdKaW9wIeBh1NK2yLioNtKUomw10mqBqXd6yo41HZ199K2ektu5uIOnl7bSUowvqGW8xZM473nzWPZohbeMHMSNTVO+KTqVbBgm1LqiYibgfvJpna/M6X0bETclFt/O3AK8M2I6CWbQOCGkbYtVK2SdLjsdZKqgb3u6OntSzy9tnPgfrJtL29hb08fdTXB2fOm8J8vPZFli1pYPHcKDXVO+CT1i5Qq51Kt1tbW1NbWVuwyJJWQiFiRUmotdh1jyV4naSh7XflKKbFy449/Y8oAACAASURBVI6BU4t/smoT27uyCZ9OPnYSFy5qYdmiFpYumMaERid8UnUbqdf5t0OSJEk6il7r7Bo4Ivvoyg42bMsmfJo7tYl3nDGLCxa1cMEJ02lxwidp1Ay2kiRJUgF17u7mp6s2DYTZlRuzCZ+mTWjg/BOmZ0dlT2hh3nQnfJIOl8FWkiRJGkNd3b2seHlL7ojsJp5es5W+BE31tSxdMI1rz53HBYumc8qxk53wSRojBltJkiTpCPT2JZ5Z28mjK3MTPq3ewp6ePmprgrOOm8LNbzmRZSdM5+x5U53wSSoQg60kSZJ0CFJKrOrYyWPtHTzS3sFPVm5iW96ET+8773guPHE6SxdMZ6ITPklHhX/TJEmSpIPYsK1/wqdNPLayg/WdXQDMmdLE5acfy7JFLVxwQgvHTHLCJ6kYDLaSJEnSENu6uvnpyk08tnITj7R30P76DgCmjK/nghOmc3Nuwqfjp48nwutkpWIz2EqSJKnqdXX38vgrW3isPQuyT+UmfBpXX8PSBdN59zlzWbaohVNnOeGTVIoMtpIkSao6vX2J59Zt45H2Dh5b2cF/vLR5YMKnxXOb+fgli1i2qIWz502hsa622OVKOgiDrSRJkipeSonVm3ZlQba9g8dWbqJzdzcAJ82cyHVL53HhohbOWziNSePqi1ytpENlsJUkSVJFen17F4+1b8pN+tTButyET7Obx/G2U2dy4aIWLjhhOjMmjytypZKOlMFWkiRJFWF7Vzc/W7V54PTiX2zIJnxqbsomfPqtS1q4cFEL853wSao4BltJkiSVrW1d3fzVw6t4tL2DJ9d00tuXaKyrYemCaVxz9lwuXNTCqbMnU+uET1JFM9hKkiSpbDXW1fCNR1ezaMZEbrpoIcsWtbBk3lTG1Tvhk1RNDLaSJEkqW411tbT97lsNslKVqyl2AZIkSdKRMNRKMthKkiRJksqawVaSJEmSVNYMtpIkSZKksmawlSRJkiSVNYOtJEmSJKmsGWwlSZIkSWXNYCtJkiRJKmsGW0mSJElSWTPYSpIkSZLKmsFWkiRJklTWDLaSJEmSpLJmsJUkSZIklTWDrSRJkiSprBlsJUmSJEllzWArSZIkSSprBltJkiRJUlkraLCNiMsj4sWIaI+IW4ZZ3xwR/xwRT0bEsxFxfd661RHxdEQ8ERFthaxTko6EvU5SNbDXSSpldYXacUTUAl8H3gasAZZHxH0ppefyhn0ceC6ldGVEHAO8GBHfTintza2/JKXUUagaJelI2eskVQN7naRSV8gjtkuB9pTSqlxDuxu4asiYBEyKiAAmApuBngLWJEljzV4nqRrY6ySVtEIG2znAq3nv1+SW5fsacAqwDnga+M8ppb7cugQ8EBErIuLGA31IRNwYEW0R0bZx48axq16SRsdeJ6ka2OsklbRCBtsYZlka8v7twBPAbOAs4GsRMTm3bllKaQlwBfDxiHjzcB+SUrojpdSaUmo95phjxqh0SRo1e52kamCvk1TSChls1wDH5b2fS/YNXr7rgX9MmXbgJeBkgJTSutzz68C9ZKfASFKpsddJqgb2OkklrZDBdjlwYkQsiIgG4FrgviFjXgEuBYiImcAbgFURMSEiJuWWTwAuA54pYK2SdLjsdZKqgb1OUkkr2KzIKaWeiLgZuB+oBe5MKT0bETfl1t8O/D5wV0Q8TXaKy2dTSh0RsRC4N5t7gDrgb1NKPyhUrZJ0uOx1kqqBvU5SqYuUhl4eUb5aW1tTW5u3RpM0KCJWpJRai13HWLLXSRrKXiepGozU6wp5KrIkSZIkSQVnsJUkSZIklTWDrSRJkiSprBlsJUmSJEllzWArSZIkSSprBltJkiRJUlkz2EqSJEmSyprBVpIkSZJU1gy2kiRJkqSyZrCVJEmSJJU1g60kSZIkqawZbCVJkiRJZc1gK0mSJEkqawZbSZIkSVJZO2iwjYh3RoQBWFJFs9dJqgb2OkmVajSN7VrglxFxa0ScUuiCJKlI7HWSqoG9TlJFOmiwTSm9HzgbWAl8IyJ+EhE3RsSkglcnSUeJvU5SNbDXSapUozoVJaW0DfgH4G5gFnAN8HhEfKKAtUnSUWWvk1QN7HWSKtForrG9MiLuBf4dqAeWppSuABYDny5wfZJ0VNjrJFUDe52kSlU3ijHvBv44pfRw/sKU0q6I+FBhypKko85eJ6ka2OskVaTRBNsvAev730REEzAzpbQ6pfRvBatMko4ue52kamCvk1SRRnON7d8DfXnve3PLJKmS2OskVQN7naSKNJpgW5dS2tv/Jve6oXAlSVJR2OskVQN7naSKNJpguzEifrX/TURcBXQUriRJKgp7naRqYK+TVJFGc43tTcC3I+JrQACvAh8oaFWSdPTZ6yRVA3udpIp00GCbUloJvDEiJgKRUtpe+LIk6eiy10mqBvY6SZVqNEdsiYh3AKcB4yICgJTSVwpYlyQddfY6SdXAXiepEh30GtuIuB14D/AJslNW3g0cX+C6JOmostdJqgb2OkmVajSTR12QUvoAsCWl9HvA+cBxhS1Lko46e52kamCvk1SRRhNsu3LPuyJiNtANLChcSZJUFPY6SdXAXiepIo3mGtt/jogpwG3A40AC/qqgVUnS0Wevk1QN7HWSKtKIR2wjogb4t5TS1pTSP5Bdg3FySumLo9l5RFweES9GRHtE3DLM+uaI+OeIeDIino2I60e7rSSNFXudpGpgr5NUyUYMtimlPuCP8t7vSSl1jmbHEVELfB24AjgVuC4iTh0y7OPAcymlxcDFwB9FRMMot5WkMWGvk1QN7HWSKtlorrF9ICJ+Pfrngx+9pUB7SmlVSmkvcDdw1ZAxCZiU2/dEYDPQM8ptJWks2eskVQN7naSKNJprbD8FTAB6IqKLbGr4lFKafJDt5gCv5r1fA5w3ZMzXgPuAdcAk4D0ppb6IGM22kjSW7HWSqoG9TlJFOmiwTSlNOsx9D/dNYBry/u3AE8BbgBOAH0bEj0e5bfYhETcCNwLMmzfvMEuVVO3sdZKqgb1OUqU6aLCNiDcPtzyl9PBBNl3DvvdFm0v2DV6+64GvppQS0B4RLwEnj3Lb/jruAO4AaG1tHbZJStLB2OskVQN7naRKNZpTkT+T93oc2XUSK8i+jRvJcuDEiFgArAWuBd47ZMwrwKXAjyNiJvAGYBWwdRTbStJYstdJqgb2OkkVaTSnIl+Z/z4ijgNuHcV2PRFxM3A/UAvcmVJ6NiJuyq2/Hfh94K6IeJrsNJXPppQ6cp+z37aH9JNJ0iGw10mqBvY6SZUqsrNFDmGDbKa7p1JKZxSmpMPX2tqa2trail2GpBISEStSSq2HsZ29TlLZsNdJqgYj9brRXGP7/zN4gX8NcBbw5NiVJ0nFZ6+TVA3sdZIq1Wiusc3/qqwH+E5K6dEC1SNJxWKvk1QN7HWSKtJogu09QFdKqRcgImojYnxKaVdhS5Oko8peJ6ka2OskVaSaUYz5N6Ap730T8K+FKUeSisZeJ6ka2OskVaTRBNtxKaUd/W9yr8cXriRJKgp7naRqYK+TVJFGE2x3RsSS/jcRcQ6wu3AlSVJR2OskVQN7naSKNJprbP8L8PcRsS73fhbwnsKVJElFYa+TVA3sdZIq0kGDbUppeUScDLyB7GbbL6SUugtemSQdRfY6SdXAXiepUh30VOSI+DgwIaX0TErpaWBiRHys8KVJ0tFjr5NUDex1kirVaK6x/UhKaWv/m5TSFuAjhStJkorCXiepGtjrJFWk0QTbmoiI/jcRUQs0FK4kSSoKe52kamCvk1SRRjN51P3A30XE7UACbgL+paBVSdLRZ6+TVA3sdZIq0miC7WeBG4HfIptk4OdkM+hJUiWx10mqBvY6SRXpoKcip5T6gJ8Cq4BW4FLg+QLXJUlHlb1OUjWw10mqVAc8YhsRJwHXAtcBm4DvAqSULjk6pUlS4dnrJFUDe52kSjfSqcgvAD8GrkwptQNExCePSlWSdPTY6yRVA3udpIo20qnIvw68BjwYEX8VEZeSXYshSZXEXiepGtjrJFW0AwbblNK9KaX3ACcDPwI+CcyMiL+IiMuOUn2SVFD2OknVwF4nqdKNZvKonSmlb6eU3gnMBZ4Abil4ZZJ0FNnrJFUDe52kSnXQYJsvpbQ5pfSXKaW3FKogSSo2e52kamCvk1RJDinYSpIkSZJUagy2kiRJkqSyZrCVJEmSJJU1g60kSZIkqawZbCVJkiRJZc1gK0mSJEkqawZbSZIkSVJZM9hKkiRJksqawVaSJEmSVNYMtpIkSZKksmawlSRJkiSVNYOtJEmSJKmsFTTYRsTlEfFiRLRHxC3DrP9MRDyRezwTEb0RMS23bnVEPJ1b11bIOiXpSNjrJFUDe52kUlZXqB1HRC3wdeBtwBpgeUTcl1J6rn9MSuk24Lbc+CuBT6aUNuft5pKUUkehapSkI2Wvk1QN7HWSSl0hj9guBdpTSqtSSnuBu4GrRhh/HfCdAtYjSYVgr5NUDex1kkpaIYPtHODVvPdrcsv2ExHjgcuBf8hbnIAHImJFRNxYsCol6cjY6yRVA3udpJJWsFORgRhmWTrA2CuBR4ecrrIspbQuImYAP4yIF1JKD+/3IVlzvBFg3rx5R1qzJB0qe52kamCvk1TSCnnEdg1wXN77ucC6A4y9liGnq6SU1uWeXwfuJTsFZj8ppTtSSq0ppdZjjjnmiIuWpENkr5NUDex1kkpaIYPtcuDEiFgQEQ1kTe6+oYMiohm4CPhe3rIJETGp/zVwGfBMAWuVpMNlr5NUDex1kkpawU5FTin1RMTNwP1ALXBnSunZiLgpt/723NBrgAdSSjvzNp8J3BsR/TX+bUrpB4WqVZIOl71OUjWw10kqdZHSgS6PKD+tra2prc1bo0kaFBErUkqtxa5jLNnrJA1lr5NUDUbqdYWcPEo6qrp7+9iwrYvXOrvo6u4rdjkqkAhYtqil2GVIkiSphBhsVRb6+hIdO/ewfmsX6zt3s3ZrF+u37mZ9ZxfrOnezfmsXr2/voq9yTkDQAdTXBr/8f3+l2GVIkiSphBhsVXQpJTp3d7MuF1rXdWahdd3W3OvO3Wzo3MPe3n2PwjbW1TB7ShOzp4zjwhNbmN08jllTmpjVPI4Jjf7RrlTD3W9CkiRJ1c3//avgdu7pyQJrf3DNPa/v7MrC69Yudnf37rNNXU0wc/I4Zk8Zx9nHTWX2GVmAndWcBdfZU5qYOr6e3EQUkiRJkqqYwVZHZE9PLxs697CuMzvC2h9W8587d3fvs00EHDOxkVlTmjhp5iQuOmnGQGidPSULrS0TG6mtMbRKkiRJOjiDrQ6oty/x+vauwSOsW7tYu3V33tHWLjp27Nlvuynj65nV3MTcqU2cO38as6aMY3bekdaZk8fRUFfIWyhLkiRJqiYG2yqVUmLTzr2s39o/+VL/REyD17du2L6H3iGzMU1oqB24jvWUYycze0rTYHCdMo5ZzeMY3+AfK0mSJElHjwmkQm3r6s5C69bdA7MG9z/3H3Hd07PvZEwNtTUD4fSNC6fnXg+eHjyruYnJ4+q8rlWSJElSSTHYlqGu7t59rmMdOpvw+s4uduzp2WebmoCZk7PQevqcZi477VhmNQ8G11nNTUyf0ECN17VKkiRJKjMG2xLT3dvHa51drO/s2m8m4XW561u37Oreb7uWiQ3Mam5iQcsEli1q2WcyplnNTcyY1Ehdrde1SpIkSao8BtujqK8v0bFjT24CpsFZg/MD7Ovb95D2vayVyePqcqcCj+OseVOy+7U2Nw3cw3Xm5HGMq68tzg8lSZIkSUVmsB0jKSW27ure5zrWtXmzCa/r3M2GbV109+6bWsfV1zA7F1LffOIxzJrSlAXXvOeJjf42SZIkSdKBmJhGaceenmy24P5ZgweeB4NrV/e+kzHV1QTHNmczBp9z/FRmNTcxJ3dqcP9MwlPG1zsZkyRJkiQdAYMt2WRMr3XuO2tw/kRMa7fuZnvXvpMxRcCMSY3Mam7i5FmTuOTkGQP3aZ2dO9raMrHRyZgkSZIkqcCqMti+8No2/r8HfjFwfWvHjr37jZk6vp5ZzU3MnTqepQum7TMR06zm7LrWhjonY5IkSZKkYqvKYNvXBy917GTWlCZOmz15yL1as/Da1OBkTJIkSZJUDqoy2J46ezI//NRFxS5DkiRJkjQGPJdWkiRJklTWDLaSJEmSpLJmsJUkSZIklTWDrSRJkiSprBlsJUmSJEllzWArSZIkSSprBltJkiRJUlkz2EqSJEmSyprBVpIkSZJU1gy2kiRJkqSyZrCVJEmSJJU1g60kSZIkqawZbCVJkiRJZc1gK0mSJEkqawZbSZIkSVJZK2iwjYjLI+LFiGiPiFuGWf+ZiHgi93gmInojYtpotpWkUmGvk1QN7HWSSlnBgm1E1AJfB64ATgWui4hT88eklG5LKZ2VUjoL+BzwUEpp82i2laRSYK+TVA3sdZJKXSGP2C4F2lNKq1JKe4G7gatGGH8d8J3D3FaSisVeJ6ka2OsklbRCBts5wKt579fklu0nIsYDlwP/cBjb3hgRbRHRtnHjxiMuWpIOkb1OUjWw10kqaYUMtjHMsnSAsVcCj6aUNh/qtimlO1JKrSml1mOOOeYwypSkI2Kvk1QN7HWSSlohg+0a4Li893OBdQcYey2Dp6sc6raSVEz2OknVwF4nqaQVMtguB06MiAUR0UDW5O4bOigimoGLgO8d6raSVALsdZKqgb1OUkmrK9SOU0o9EXEzcD9QC9yZUno2Im7Krb89N/Qa4IGU0s6DbVuoWiXpcNnrJFUDe52kUhcpHejyiPLT2tqa2trail2GpBISEStSSq3FrmMs2eskDWWvk1QNRup1hTwVWZIkSZKkgjPYSpIkSZLKmsFWkiRJklTWDLaSJEmSpLJmsJUkSZIklTWDrSRJkiSprBlsJUmSJEllzWArSZIkSSprBltJkiRJUlkz2EqSJEmSyprBVpIkSZJU1gy2kiRJkqSyZrCVJEmSJJU1g60kSZIkqawZbCVJkiRJZc1gK0mSJEkqawZbSZIkSVJZM9hKkiRJksqawVaSJEmSVNYMtpIkSZKksmawlSRJkiSVNYOtJEmSJKmsGWwlSZIkSWXNYCtJkiRJKmsGW0mSJElSWTPYSpIkSZLKmsFWkiRJklTWDLaSJEmSpLJmsJUkSZIklTWDrSRJkiSprBlsJUmSJEllzWArSZIkSSprBQ22EXF5RLwYEe0RccsBxlwcEU9ExLMR8VDe8tUR8XRuXVsh65SkI2Gvk1QN7HWSSlldoXYcEbXA14G3AWuA5RFxX0rpubwxU4A/By5PKb0SETOG7OaSlFJHoWqUpCNlr5NUDex1kkpdIY/YLgXaU0qrUkp7gbuBq4aMeS/wjymlVwBSSq8XsB5JKgR7naRqYK+TVNIKGWznAK/mvV+TW5bvJGBqRPwoIlZExAfy1iXggdzyGw/0IRFxY0S0RUTbxo0bx6x4SRole52kamCvk1TSCnYqMhDDLEvDfP45wKVAE/CTiPhpSukXwLKU0rrcaSw/jIgXUkoP77fDlO4A7gBobW0dun9JKjR7naRqYK+TVNIKecR2DXBc3vu5wLphxvwgpbQzd83Fw8BigJTSutzz68C9ZKfASFKpsddJqgb2OkklrZBHbJcDJ0bEAmAtcC3ZtRf5vgd8LSLqgAbgPOCPI2ICUJNS2p57fRnwlQLWKh1Qd3c3a9asoaurq9ilaATjxo1j7ty51NfXH+2PttepItjryoO9Tjoy9rrycDi9rmDBNqXUExE3A/cDtcCdKaVnI+Km3PrbU0rPR8QPgKeAPuCvU0rPRMRC4N6I6K/xb1NKPyhUrdJI1qxZw6RJk5g/fz65P5MqMSklNm3axJo1a1iwYMHR/mx7nSqCva702eukI2evK32H2+sKecSWlNL3ge8PWXb7kPe3AbcNWbaK3KkrUrF1dXXZ/EpcRDB9+nSKNdGIvU6VwF5X+ux10pGz15W+w+11hbzGVqoYNr/S5++RdOT8e1T6/D2Sjpx/j0rf4fweGWylErd161b+/M///LC3/5M/+RN27do1hhVJ0tiz10mqBva6wjHYSiWuEhpgT09PUT9fUumz10mqBva6wjHYSiXulltuYeXKlZx11ll85jOfAeC2227j3HPP5cwzz+RLX/oSADt37uQd73gHixcv5vTTT+e73/0uf/Znf8a6deu45JJLuOSSS/bb91e+8hXOPfdcTj/9dG688UZSym4Z2N7ezlvf+lYWL17MkiVLWLlyJQC33norZ5xxBosXL+aWW24B4OKLL6atrQ2Ajo4O5s+fD8Bdd93Fu9/9bq688kouu+wyduzYwaWXXsqSJUs444wz+N73vjdQxze/+U3OPPNMFi9ezG/8xm+wfft2FixYQHd3NwDbtm1j/vz5A+8lVR57nb1Oqgb2ugL2upRSxTzOOeecJI215557rqif/9JLL6XTTjtt4P3999+fPvKRj6S+vr7U29ub3vGOd6SHHnoo3XPPPenDH/7wwLitW7emlFI6/vjj08aNG4fd96ZNmwZev//970/33XdfSimlpUuXpn/8x39MKaW0e/futHPnzvT9738/nX/++Wnnzp37bHvRRRel5cuXp5RS2rhxYzr++ONTSil94xvfSHPmzBkY193dnTo7OwfGnXDCCamvry8988wz6aSTThqosX/8Bz/4wXTvvfemlFL6y7/8y/SpT33qoL9Ww/1eAW2pBPrTWD7sdSoEe529rtQe9joVgr2ucntdQWdFlirN7/3zszy3btuY7vPU2ZP50pWnjXr8Aw88wAMPPMDZZ58NwI4dO/jlL3/Jm970Jj796U/z2c9+lne+85286U1vOui+HnzwQW699VZ27drF5s2bOe2007j44otZu3Yt11xzDZDdRwzgX//1X7n++usZP348ANOmTTvo/t/2trcNjEsp8fnPf56HH36Ympoa1q5dy4YNG/j3f/933vWud9HS0rLPfj/84Q9z6623cvXVV/ONb3yDv/qrvxr1r5GkI2Ovs9dJ1cBeV1m9zmArlZmUEp/73Of46Ec/ut+6FStW8P3vf5/Pfe5zXHbZZXzxi1884H66urr42Mc+RltbG8cddxxf/vKX6erqIvsybPjPHW6Gurq6Ovr6+gb2mW/ChAkDr7/97W+zceNGVqxYQX19PfPnzx/4vOH2u2zZMlavXs1DDz1Eb28vp59++gF/FkmVx14nqRrY68aOwVY6BIfyDdxYmTRpEtu3bx94//a3v50vfOELvO9972PixImsXbuW+vp6enp6mDZtGu9///uZOHEid9111z7b939z1q+/WbW0tLBjxw7uuece3vWudzF58mTmzp3LP/3TP3H11VezZ88eent7ueyyy/jKV77Ce9/7XsaPH8/mzZuZNm0a8+fPZ8WKFSxdupR77rnngD9HZ2cnM2bMoL6+ngcffJCXX34ZgEsvvZRrrrmGT37yk0yfPn1gvwAf+MAHuO666/jCF74wlr+kkg7CXmevk6qBva6yep3BVipx06dPZ9myZZx++ulcccUV3HbbbTz//POcf/75AEycOJFvfetbtLe385nPfIaamhrq6+v5i7/4CwBuvPFGrrjiCmbNmsWDDz44sN8pU6bwkY98hDPOOIP58+dz7rnnDqz7m7/5Gz760Y/yxS9+kfr6ev7+7/+eyy+/nCeeeILW1lYa/m979xpbVb3mcfz32IpYIgrozHHoBDqTw4C70JYWUEkFLxAOhjlGp3KEhIhHzPHSODFicMRAYjQzgReMerzUOaTKi0GCx0EMeBIcyLzBCF7AETAquzk0MFxaqDiKWHnmBXUPlxb2avfquuzvJ2nSvfZ/rfV0PVm/8OzdXQYM0MyZM/Xcc8/p8ccf1913361Vq1bplltu6fHnmDt3rmbNmqW6ujpVV1dr9OjRkqRMJqOnnnpKU6ZMUUlJiWpqanLhPXfuXC1evFj33HNPoS8rgJgh68g6oBiQdeFlnfX09nQS1dXV+c9/xQsolN27d2vMmDFRl1GU1q5dq3Xr1mnVqlV5re+uV2b2kbvXhVFfVMg6hIGsiw5Z1z2yDmEg66ITdtbxji2AWGpsbNTGjRu1YcOGqEsBgNCQdQCKQX9kHYMtgFh64YUXoi4BAEJH1gEoBv2RdZeEfgYAAAAAAELEYAsAAAAASDQGWwAAAABAojHYAgAAAAASjcEWiLljx47ppZde6tW+M2fO1LFjxwpcEQAUHlkHoBiQdeFhsAVi7kIB+NNPP11w3w0bNuiqq64Ko6w+cXedOnUq6jIAxAhZB6AYkHXhYbAFYm7RokX6+uuvVV1drYULF2rLli26+eabNWfOHI0dO1aSdMcdd6i2tlaZTEZNTU25fUeOHKkjR46opaVFY8aM0YIFC5TJZDR9+nR9//33551r/fr1mjRpkmpqanTbbbfp4MGDkqRvv/1W8+fP19ixYzVu3Di99dZbkqT33ntP48ePV1VVlW699VZJ0tKlS7V8+fLcMSsrK9XS0pKr4aGHHtL48eO1b98+Pfjgg6qrq1Mmk9GSJUty+2zbtk033nijqqqqNHHiRB0/flz19fX69NNPc2smT56snTt3FvBKA4gSWUfWAcWArAsx69w9NV+1tbUOFNquXbsiPX82m/VMJpN7vHnzZi8rK/O9e/fmtrW1tbm7+3fffeeZTMaPHDni7u4jRozww4cPezab9ZKSEv/kk0/c3b2hocFXrVp13rna29v91KlT7u7+2muv+WOPPebu7k888YQ/+uijZ607dOiQl5eX5+r4uYYlS5b4smXLcmszmYxns1nPZrNuZr5169bz6u7s7PQpU6b4jh07/IcffvCKigr/8MMP3d29o6PDf/zxR29ubs7V8MUXX3h393t3vZK03WOQT4X8IusQBrKOrIvbF1mHMJB16c260r6NGLGefQAACixJREFUxUCR2bhI+p/PCnvMX4yVfvXPgXaZOHGiKioqco+ff/55vf3225Kkffv26csvv9SwYcPO2qeiokLV1dWSpNraWrW0tJx33NbWVs2ePVsHDhzQyZMnc+fYtGmTVq9enVs3ZMgQrV+/XjfddFNuzdChQy9a94gRI3T99dfnHq9Zs0ZNTU3q7OzUgQMHtGvXLpmZrr32Wk2YMEGSNHjwYElSQ0ODnnnmGS1btkwrV67Uvffee9HzAeglsk4SWQekHlknKT1Zx68iAwk0aNCg3PdbtmzRpk2btHXrVu3YsUM1NTU6ceLEeftcdtllue9LSkrU2dl53prGxkY98sgj+uyzz/Tqq6/mjuPuMrOz1na3TZJKS0vP+pzFmbWcWXc2m9Xy5cv1/vvva+fOnbr99tt14sSJHo9bVlamadOmad26dVqzZo3mzJnT7bUBkB5kHVkHFAOyrjBZxzu2QBABX4ErhCuuuELHjx/v8fmOjg4NGTJEZWVl2rNnjz744INen6ujo0PDhw+XJL3++uu57dOnT9eLL76oFStWSJKOHj2qG264QQ8//LCy2awqKirU3t6uoUOHauTIkXr33XclSR9//LGy2Wy35/rmm280aNAgXXnllTp48KA2btyoqVOnavTo0dq/f7+2bdumCRMm6Pjx47r88stVWlqq+++/X7NmzVJ9fX1eryQC6CWyThJZB6QeWScpPVnHO7ZAzA0bNkyTJ09WZWWlFi5ceN7zM2bMUGdnp8aNG6enn376rF8JCWrp0qVqaGhQfX29rr766tz2xYsX6+jRo6qsrFRVVZU2b96sa665Rk1NTbrzzjtVVVWl2bNnS5Luuusutbe3q7q6Wi+//LJGjRrV7bmqqqpUU1OjTCaj++67T5MnT5YkDRgwQG+++aYaGxtVVVWladOm5V4drK2t1eDBgzV//vxe/4wA4omsI+uAYkDWhZd1dvozuOlQV1fn27dvj7oMpMzu3bs1ZsyYqMuApP3792vq1Knas2ePLrnk/NfluuuVmX3k7nX9VWN/IOsQBrIuPsi608g6hIGsi49CZx3v2AJIhDfeeEOTJk3Ss88+2234AUAakHUAikEYWcdnbAEkwrx58zRv3ryoywCAUJF1AIpBGFnHS4EAAAAAgERjsAXykKbPoqcVPQL6jvso/ugR0HfcR/HXmx4x2AIXMXDgQLW1tRGCMebuamtr08CBA6MuBUgssi7+yDqg78i6+Ott1vEZW+AiysvL1draqsOHD0ddCi5g4MCBKi8vj7oMILHIumQg64C+IeuSoTdZF+pga2YzJP2rpBJJ/+bu5/0vyGY2VdIKSZdKOuLuU/LdF+gPl156qSoqKqIuAzFG1iENyDpcDFmHNCDr0iu0wdbMSiT9XtI0Sa2StpnZO+6+64w1V0l6SdIMd/+zmf1FvvsCQByQdQCKAVkHIO7C/IztRElfuftedz8pabWkX5+zZo6kP7r7nyXJ3Q8F2BcA4oCsA1AMyDoAsRbmYDtc0r4zHrd2bTvTKElDzGyLmX1kZvMC7AsAcUDWASgGZB2AWAvzM7bWzbZz//xYqaRaSbdKulzSVjP7IM99T5/E7AFJD3Q9PGFmn3ez7EpJHd1sv1rSke6OG4GeaozqmEH3zWf9xdZc6PmenktCb6Vk9zfftf3V36C9HRFgbW+QdcHF6X5IStb19By9Ldy+ZN2FkXXBcT9Edz+ELcm9zXd9XHvbc9a5eyhfkm6Q9KczHj8p6clz1iyStPSMx3+Q1JDPvj2csyng9u1h/fy9uF7d1hjVMYPum8/6i6250PNJ7m3S+5vv2v7qbwx7S9YFv2axuR+SknU9PUdvC7cvWXfRn5usC37NuB/Sez8ktrf5rk9ib8P8VeRtkn5pZhVmNkDSbyS9c86adZLqzazUzMokTZK0O899u7M+4PY4CaPGvhwz6L75rL/Ymgs9n+TeSsnub75ri7W/ZF1wcbofkpJ1+Z47anHqbdB9yboLI+uC435I7/2Q5N7muz5xvbWuSTmcg5vN1Ok/+V4iaaW7P2tmv5Mkd3+la81CSfMlndLpP/++oqd9Q6hvu7vXFfq4iB69Ta849pasQ1TobXrFsbdkHaJCb9OrkL0NdbCNOzN7wN2boq4DhUdv04veBsc1Sy96m170NjiuWXrR2/QqZG+LerAFAAAAACRfmJ+xBQAAAAAgdAy2AAAAAIBEY7AFAAAAACQag20XMxtkZq+b2WtmNjfqelBYZvY3ZvYHM1sbdS0oLDO7o+u+XWdm06OuJ+7IunQj69KLrAuGrEs3si69+pJ1qR5szWylmR0ys/8+Z/sMM/vCzL4ys0Vdm++UtNbdF0j6+34vFoEF6a+773X330ZTKYIK2Nv/6Lpv75U0O4JyI0fWpRtZl15kXTBkXbqRdenVX1mX6sFWUrOkGWduMLMSSb+X9CtJ10m6x8yuk1QuaV/Xsp/6sUb0XrPy7y+SpVnBe7u46/li1CyyLs2aRdalVbPIuiCaRdalWbPIurRqVj9kXaoHW3f/L0nt52yeKOmrrld6TkpaLenXklp1OgSllF+XtAjYXyRIkN7aaf8iaaO7f9zftcYBWZduZF16kXXBkHXpRtalV39lXTHe6MP1/6/gSaeDb7ikP0q6y8xelrQ+isJQEN3218yGmdkrkmrM7MloSkMf9XTvNkq6TdI/mNnvoigspsi6dCPr0ousC4asSzeyLr0KnnWlhastMaybbe7u/ytpfn8Xg4Lrqb9tkviHQLL11NvnJT3f38UkAFmXbmRdepF1wZB16UbWpVfBs64Y37FtlfTXZzwul7Q/olpQePQ3vehtMFyvdKO/6UVvg+F6pRv9Ta+C97YYB9ttkn5pZhVmNkDSbyS9E3FNKBz6m170NhiuV7rR3/Sit8FwvdKN/qZXwXub6sHWzP5d0lZJf2dmrWb2W3fvlPSIpD9J2i1pjbt/HmWd6B36m170NhiuV7rR3/Sit8FwvdKN/qZXf/XW3L3v1QIAAAAAEJFUv2MLAAAAAEg/BlsAAAAAQKIx2AIAAAAAEo3BFgAAAACQaAy2AAAAAIBEY7AFAAAAACQagy1Sxcx+YWarzexrM9tlZhvMbFTUdQFAIZF1AIoBWYcgGGyRGmZmkt6WtMXd/9bdr5P0T5L+MtrKAKBwyDoAxYCsQ1ClURcAFNDNkn5091d+3uDun0ZYDwCEgawDUAzIOgTCO7ZIk0pJH0VdBACEjKwDUAzIOgTCYAsAAAAASDQGW6TJ55Jqoy4CAEJG1gEoBmQdAmGwRZr8p6TLzGzBzxvMbIKZTYmwJgAoNLIOQDEg6xCIuXvUNQAFY2Z/JWmFTr/Cd0JSi6R/dPcvo6wLAAqJrANQDMg6BMFgCwAAAABINH4VGQAAAACQaAy2AAAAAIBEY7AFAAAAACQagy0AAAAAINEYbAEAAAAAicZgCwAAAABINAZbAAAAAECiMdgCAAAAABLt/wBKx7OY58yizAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1152x432 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# converting C to numeric type for plotting on x-axis\n",
    "cv_results['param_C'] = cv_results['param_C'].astype('int')\n",
    "\n",
    "# # plotting\n",
    "plt.figure(figsize=(16,6))\n",
    "\n",
    "# subplot 1/3\n",
    "plt.subplot(131)\n",
    "gamma_01 = cv_results[cv_results['param_gamma']==0.01]\n",
    "\n",
    "plt.plot(gamma_01[\"param_C\"], gamma_01[\"mean_test_score\"])\n",
    "plt.plot(gamma_01[\"param_C\"], gamma_01[\"mean_train_score\"])\n",
    "plt.xlabel('C')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title(\"Gamma=0.01\")\n",
    "plt.ylim([0.60, 1])\n",
    "plt.legend(['test accuracy', 'train accuracy'], loc='lower right')\n",
    "plt.xscale('log')\n",
    "\n",
    "# subplot 2/3\n",
    "plt.subplot(132)\n",
    "gamma_001 = cv_results[cv_results['param_gamma']==0.001]\n",
    "\n",
    "plt.plot(gamma_001[\"param_C\"], gamma_001[\"mean_test_score\"])\n",
    "plt.plot(gamma_001[\"param_C\"], gamma_001[\"mean_train_score\"])\n",
    "plt.xlabel('C')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title(\"Gamma=0.001\")\n",
    "plt.ylim([0.60, 1])\n",
    "plt.legend(['test accuracy', 'train accuracy'], loc='lower right')\n",
    "plt.xscale('log')\n",
    "\n",
    "\n",
    "# subplot 3/3\n",
    "plt.subplot(133)\n",
    "gamma_0001 = cv_results[cv_results['param_gamma']==0.0001]\n",
    "\n",
    "plt.plot(gamma_0001[\"param_C\"], gamma_0001[\"mean_test_score\"])\n",
    "plt.plot(gamma_0001[\"param_C\"], gamma_0001[\"mean_train_score\"])\n",
    "plt.xlabel('C')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title(\"Gamma=0.0001\")\n",
    "plt.ylim([0.60, 1])\n",
    "plt.legend(['test accuracy', 'train accuracy'], loc='lower right')\n",
    "plt.xscale('log')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the plot above, we can observe that (from higher to lower gamma / left to right):\n",
    "- At very high gamma (0.01), the model is achieving 100% accuracy on the training data, though the test score is quite low (<75%). Thus, the model is overfitting.\n",
    "\n",
    "- At gamma=0.001, the training and test scores are comparable at around C=1, though the model starts to overfit at higher values of C\n",
    "\n",
    "- At gamma=0.0001, the model does not overfit till C=10 but starts showing signs at C=100. Also, the training and test scores are slightly lower than at gamma=0.001.\n",
    "\n",
    "The best combination is gamma=0.001 and C=1 (the plot in the middle), which gives the highest test accuracy (~92%) while avoiding overfitting.\n",
    "\n",
    "\n",
    "### Final Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1, gamma=0.001)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# optimal hyperparameters\n",
    "best_C = 1\n",
    "best_gamma = 0.001\n",
    "\n",
    "# model\n",
    "svm_final = svm.SVC(kernel='rbf', C=best_C, gamma=best_gamma)\n",
    "\n",
    "# fit\n",
    "svm_final.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict\n",
    "predictions = svm_final.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.924973544973545 \n",
      "\n",
      "[[3587    0   10   10    5   15   50   12   25    1]\n",
      " [   0 4108   14   16    5    3    6   18   10    5]\n",
      " [  24   23 3407   65   44    5   36  123   54    9]\n",
      " [   4   21   86 3502    5   89   11   73   76   33]\n",
      " [   3   11   36    7 3450   13   23   43    6  110]\n",
      " [  20   29   14  114   18 3020   79   53   36   35]\n",
      " [  31   12   11    1   14   34 3521   44   25    0]\n",
      " [   4   28   27    8   36    7    1 3739    7   97]\n",
      " [  14   59   32   80   22   97   25   44 3251   41]\n",
      " [  23   13   13   50   98    7    0  176   19 3379]]\n"
     ]
    }
   ],
   "source": [
    "# evaluation: CM \n",
    "confusion = metrics.confusion_matrix(y_true = y_test, y_pred = predictions)\n",
    "\n",
    "# measure accuracy\n",
    "test_accuracy = metrics.accuracy_score(y_true=y_test, y_pred=predictions)\n",
    "\n",
    "print(test_accuracy, \"\\n\")\n",
    "print(confusion)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "The final accuracy on test data is approx. 92%. Note that this can be significantly increased by using the entire training data of 42,000 images (we have used just 10% of that!). \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
